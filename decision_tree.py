# -*- coding: utf-8 -*-
"""Decision Tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/191U7Sdu4JK5HEcjIGviURsfdtmsFmmQs

##Loading dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv("drug.csv")
df.head()

df.info()

"""##Handling missing data"""

df.isnull().sum()

df = df.fillna(df.mean())
df.isnull().sum()

"""##Checking the type of each feature (categorical or numerical)"""

nf = df.select_dtypes(include=['int', 'float'])
cf= df.select_dtypes(include=['object'])
print("numerical features: ")
print(nf.columns)
print("categorical features: ")
print(cf.columns)

"""##Apply One-Hot Encoding for Categorical Features:"""

df_encoded = pd.get_dummies(df, columns=['Sex', 'BP', 'Cholesterol'], drop_first=True)
X_encoded = df_encoded.drop('Drug', axis=1)
y_encoded = df_encoded['Drug']

"""##First Experiment"""

best_experiment = None
best_accuracy = 0.0
for i in range(5):
    # Split the data into training and testing sets
    X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=i)

    # Initialize the Decision Tree Classifier
    dt_classifier_encoded = DecisionTreeClassifier()

    # Train the model
    dt_classifier_encoded.fit(X_train_encoded, y_train_encoded)

    # Make predictions on the test set
    y_pred_encoded = dt_classifier_encoded.predict(X_test_encoded)

    # Calculate and print accuracy
    accuracy_encoded = accuracy_score(y_test_encoded, y_pred_encoded)
    print(f"Accuracy of experiment {i + 1}: {accuracy_encoded:.4f}")
    if accuracy_encoded > best_accuracy:
        best_accuracy = accuracy_encoded
        best_experiment = {'Experiment': i + 1}

# Print details of the best-performing model after all experiments
if best_experiment is not None:
    print(f"\nBest Model: Experiment {best_experiment['Experiment']}")

"""##Second Experiment

## Lists to store statistics
"""

split_ratios = np.arange(0.3, 0.8, 0.1)
mean_accuracies = []
max_accuracies = []
min_accuracies = []
mean_tree_sizes = []
max_tree_sizes = []
min_tree_sizes = []

"""## Perform the experiment for each training set size"""

for split_ratio in split_ratios:
    mean_accuracy_per_split = []
    max_accuracy_per_split = []
    min_accuracy_per_split = []
    mean_tree_size_per_split = []
    max_tree_size_per_split = []
    min_tree_size_per_split = []

    for i in range(5):
        # Split the data into training and testing sets
        X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_encoded, y_encoded, test_size=1 - split_ratio, random_state=i)

        # Initialize the Decision Tree Classifier
        dt_classifier_split = DecisionTreeClassifier()

        # Train the model
        dt_classifier_split.fit(X_train_split, y_train_split)

        # Make predictions on the test set
        y_pred_split = dt_classifier_split.predict(X_test_split)

        # Calculate accuracy
        accuracy_split = accuracy_score(y_test_split, y_pred_split)

        # Calculate tree size (number of nodes)
        tree_size_split = dt_classifier_split.tree_.node_count

        # Store accuracy and tree size for each seed
        mean_accuracy_per_split.append(accuracy_split)
        max_accuracy_per_split.append(accuracy_split)
        min_accuracy_per_split.append(accuracy_split)
        mean_tree_size_per_split.append(tree_size_split)
        max_tree_size_per_split.append(tree_size_split)
        min_tree_size_per_split.append(tree_size_split)

    # Calculate mean, max, and min statistics for each split ratio
    mean_accuracies.append(np.mean(mean_accuracy_per_split))
    max_accuracies.append(np.max(max_accuracy_per_split))
    min_accuracies.append(np.min(min_accuracy_per_split))
    mean_tree_sizes.append(np.mean(mean_tree_size_per_split))
    max_tree_sizes.append(np.max(max_tree_size_per_split))
    min_tree_sizes.append(np.min(min_tree_size_per_split))

"""## Create a report"""

report_df = pd.DataFrame({
    'Split Ratio': split_ratios,
    'Mean Accuracy': mean_accuracies,
    'Max Accuracy': max_accuracies,
    'Min Accuracy': min_accuracies,
    'Mean Tree Size': mean_tree_sizes,
    'Max Tree Size': max_tree_sizes,
    'Min Tree Size': min_tree_sizes
})

"""## Print the report"""

print(report_df)

"""## Accuracy vs Training Set Size Plot"""

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(split_ratios, mean_accuracies, label='Mean Accuracy')
plt.plot(split_ratios, max_accuracies, label='Max Accuracy', linestyle='--')
plt.plot(split_ratios, min_accuracies, label='Min Accuracy', linestyle='--')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Training Set Size')
plt.legend()

"""## Tree Size vs Training Set Size Plot"""

plt.subplot(1, 2, 2)
plt.plot(split_ratios, mean_tree_sizes, label='Mean Tree Size')
plt.plot(split_ratios, max_tree_sizes, label='Max Tree Size', linestyle='--')
plt.plot(split_ratios, min_tree_sizes, label='Min Tree Size', linestyle='--')
plt.xlabel('Training Set Size')
plt.ylabel('Tree Size')
plt.title('Tree Size vs Training Set Size')
plt.legend()

plt.tight_layout()
plt.show()